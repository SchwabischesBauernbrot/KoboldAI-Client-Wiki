## Quick Explainer
There are two different pseudocode techniques that have been found as best practice for storing information in memory such as relational status between characters, how the world operates, and any other desired information dense facts desired to be consistent. These are two formats, one dubbed W++ which works best with language models that have an understanding of following explicit instructions and basic code, and SBF or Square Bracket Format which works best with language models more focused only on natural language.

## W++
Language models influenced by W++ are EleutherAI's GPT-J, GPT-Neo, and Meta's Opt (Open Pre-trained Transformers) series models.

## SBF (Square Bracket Format)
Language models influenced by SBF are Meta's XGLM and Fairseq-dense series models.

## W++ and SBF Editor Link
https://nolialsea.github.io/Wpp/
