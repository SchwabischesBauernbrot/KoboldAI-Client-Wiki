## Quick Explainer
https://nolialsea.github.io/Wpp/
There are two different pseudocode techniques that have been found as best practice for storing information in memory such as relational status between characters, how the world operates, and any other desired information dense facts desired to be consistent. These are two formats, one dubbed W++ which works best with language models that have an understanding of following explicit instructions and basic code, and SBF or Square Bracket Format which works best with language models more focused only on natural language.

## W++
Language models found most compatible with W++ are EleutherAI's GPT-J, GPT-NeoX, and Meta's Opt (Open Pre-trained Transformers) series models.
https://nolialsea.github.io/Wpp/